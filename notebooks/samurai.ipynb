{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "\n",
    "from ultralytics.models.sam import SAM2VideoPredictor\n",
    "\n",
    "# Create SAM2VideoPredictor\n",
    "overrides = dict(conf=0.25, task=\"segment\", mode=\"predict\", imgsz=1024, model=\"sam2.1_b.pt\")\n",
    "predictor = SAM2VideoPredictor(overrides=overrides, samurai=True)\n",
    "\n",
    "\n",
    "# yolo_points = []\n",
    "# for result in results:\n",
    "#     for box in result.boxes:\n",
    "#         x_min, y_min, x_max, y_max = box.xyxy.cpu().numpy()[0]  # Convert to numpy array\n",
    "#         center_x = int((x_min + x_max) / 2)\n",
    "#         center_y = int((y_min + y_max) / 2)\n",
    "#         yolo_points.append([int(x_min), int(y_min), int(x_max), int(y_max)])\n",
    "#         # print(\"YOLO points:\", yolo_points)\n",
    "\n",
    "# # Example: Assign labels (adjust logic as per your requirements)\n",
    "# labels = [1] * len(yolo_points)  # Assuming all points belong to the same class\n",
    "# print(\"YOLO points:\", yolo_points)\n",
    "# # Step 2: Run SAM2VideoPredictor with points from YOLO\n",
    "# overrides = dict(conf=0.25, task=\"segment\", mode=\"predict\", imgsz=1024, model=\"sam2.1_b.pt\")\n",
    "sam_predictor = SAM2VideoPredictor(overrides=overrides, samurai=True)\n",
    "\n",
    "# # Pass YOLO points to SAM2VideoPredictor\n",
    "# results = sam_predictor(\n",
    "#     source=\"/mnt/data/demo_video/surg_sponge.avi\",\n",
    "#     points=yolo_points[0],\n",
    "#     labels=labels[0],\n",
    "# )\n",
    "\n",
    "\n",
    "# Run inference with multiple points\n",
    "# results = predictor(source=\"/mnt/data/demo_video/surg_sponge.avi\", points=[[750, 1040], [1490, 1740]], labels=[1, 1])\n",
    "\n",
    "# Run inference with multiple points prompt per object\n",
    "results = predictor(source=\"/mnt/data/demo_video/surg_sponge.avi\", points=[[979, 1016], [1082, 1133]], labels=[1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "model = YOLO(\"/mnt/data/weights/all_data_v11/yolov11_all_data_02122024_5/weights/best.pt\")\n",
    "\n",
    "results = model.predict(source=\"/mnt/data/demo_video/surg_sponge.avi\", conf=0.25, classes=[1] , device=\"0\", imgsz=1024)\n",
    "\n",
    "Run inference with single point\n",
    "results = predictor(source=\"/mnt/data/demo_video/surg_sponge.avi\", points=[[750, 1040], [750, 1740], [1490, 1740], [1490, 1040]], labels=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
